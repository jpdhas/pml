{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning - Regression\n",
    "\n",
    "*y* is a real number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "#Supervised learning: Tell the machine and input and this is the output. Two types\n",
    "#Regression: output is a real number\n",
    "#Classification: output is a class or a category\n",
    "\n",
    "'''\n",
    "+--------------+\n",
    "| frev         |\n",
    "+--------------+\n",
    "| x1 | x2 | y  |\n",
    "+----+----+----+\n",
    "| 2  | 3  | 4  |\n",
    "+----+----+----+\n",
    "| 8  | 5  | 9  |\n",
    "+----+----+----+\n",
    "| 6  | 4  | 7  |\n",
    "+----+----+----+\n",
    "| 10 | 2  | 7  |\n",
    "+----+----+----+\n",
    "| 4  | 2  | 4  |\n",
    "+----+----+----+\n",
    "| 16 | 7  | 15 |\n",
    "+----+----+----+\n",
    "'''\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "X = [\n",
    "    [2, 3],\n",
    "    [8, 5],\n",
    "    [6, 4],\n",
    "    [10, 2],\n",
    "    [4, 2],\n",
    "    [16, 7]\n",
    "]\n",
    "\n",
    "Y = [4, 9, 7, 7, 4, 15]\n",
    "\n",
    "#TBD: Fit/Train the model from observed data\n",
    "# Model understands what the problem is by giving it the input and the predicted output\n",
    "model.fit(X, Y)\n",
    "\n",
    "#TBD: Use fitted/trained model to predict for any given x1, x2\n",
    "model.predict([[8, 8]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning - Classification\n",
    "*y* is a class/category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['bar', 'foo', 'hello', 'lottery', 'prize', 'winner', 'world']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "to_array not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4c38c71a5b81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m '''\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#TBD Use fitted model to predict if the documents in test data are spam or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Spam classification (1 means document is spam):\\n====\\n{predictions}\\n====\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/pml-5f00brlu/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: to_array not found"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "Building a labelled dataset of documents\n",
    "'''\n",
    "doc0 = \"hello world\"\n",
    "doc1 = \"foo bar\"\n",
    "doc2 = \"lottery prize winner\"\n",
    "docs_train = [doc0] * 100 + [doc1] * 100 + [doc2] * 4 \n",
    "\n",
    "docs_test = [\n",
    "             \"lottery winner\",\n",
    "             \"hello foo\", \n",
    "             \"hello bar\", \n",
    "             \"lottery prize\", \n",
    "             \"world foo\",\n",
    "             \"prize winner\",\n",
    "            ]\n",
    "\n",
    "'''\n",
    "    Converting documents to feature vectors\n",
    "'''\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(docs_train).toarray()\n",
    "features = vectorizer.get_feature_names()\n",
    "print(f'Features: {features}')\n",
    "Y_train = np.array([[0] * 100 + [0] * 100 + [1.0] * 4]).reshape(204,)\n",
    "X_test = vectorizer.transform(docs_test).toarray()\n",
    "\n",
    "'''\n",
    "Choosing the model\n",
    "'''\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "'''\n",
    "    Train the model\n",
    "'''\n",
    "#TBD Fit the model to training data\n",
    "\n",
    "'''\n",
    "    Test the model\n",
    "'''\n",
    "#TBD Use fitted model to predict if the documents in test data are spam or not\n",
    "X_test = vectorizer.transform(docs_test).to_array()\n",
    "predictions = classifier.predict(X_test)\n",
    "print(f'Spam classification (1 means document is spam):\\n====\\n{predictions}\\n====\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
